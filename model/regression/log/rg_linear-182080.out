=============================================
[INFO] Job Information
---------------------------------------------
[INFO] Job Name       : rg_framework_main
[INFO] Job ID         : 182080
[INFO] Submit Dir     : /home/cseomoon/appl/af_analysis-0.1.4/model/regression/scripts
[INFO] Partition      : a5000_short
[INFO] Node List      : gpu3
[INFO] Nodes          : 1
[INFO] CPUs per Task  : 32
[INFO] Memory (MB)    : 
[INFO] User           : cseomoon
[INFO] Work Dir       : /home/cseomoon/appl/af_analysis-0.1.4/model/regression/scripts
[INFO] Tasks per Node : 1
[INFO] Dependency     : 
[INFO] GPU(s)         : 
=============================================

[INFO] Job started at : Fri Apr 25 15:52:40 KST 2025
[INFO] Job allocated on node(s): gpu3
[INFO] Job running on: gpu3
[INFO] Saving results to /home/cseomoon/appl/af_analysis-0.1.4/model/regression/results/rg_main_20250425_155240
Successfully imported BaseModelRegressor using relative path '.' in linear_models.
Successfully imported model classes using relative paths.
Successfully imported utils using relative paths.
Initialized Random Forest (rf) with params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Initialized LightGBM (lgbm) with params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression_l1', 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 0.8, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'metric': 'mae', 'verbose': -1}
Initialized XGBoost (xgb) with params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'rmse', 'feature_types': None, 'feature_weights': None, 'gamma': 0, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': 'hist', 'validate_parameters': None, 'verbosity': None}
Initialized Linear Regression pipeline (scale=True).
Initialized Ridge Regression pipeline (scale=True, alpha=1.0).
Initialized Lasso Regression pipeline (scale=True, alpha=1.0).
Initialized Elastic Net pipeline (scale=True, alpha=1.0, l1_ratio=0.5).
Using 32 CPU cores.
Results will be saved to: /home/cseomoon/appl/af_analysis-0.1.4/model/regression/results/rg_main_20250425_155240
Results saved to /home/cseomoon/appl/af_analysis-0.1.4/model/regression/results/rg_main_20250425_155240/run_arguments.json

--- Loading Data ---
Original data shape: (3650, 81)
Using 'DockQ' as the continuous target variable.
Identified 63 potential feature columns.
Checking for NaN values in potential feature columns...
Dropped 3 rows containing NaN values in one or more feature columns.
Processed Features (X) shape after NaN drop: (3647, 63)
Processed Target (y) shape after NaN drop: (3647,)
Processed Query IDs shape after NaN drop: (3647,)
Data Loading & Preprocessing Duration: 0.08 seconds

--- Starting Model Training ---
Initialized Random Forest (rf) with params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Initialized LightGBM (lgbm) with params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression_l1', 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 0.8, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'metric': 'mae', 'verbose': -1}
Initialized XGBoost (xgb) with params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'rmse', 'feature_types': None, 'feature_weights': None, 'gamma': 0, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': 'hist', 'validate_parameters': None, 'verbosity': None}
Initialized Linear Regression pipeline (scale=True).
Initialized Ridge Regression pipeline (scale=True, alpha=1.0).
Initialized Lasso Regression pipeline (scale=True, alpha=1.0).
Initialized Elastic Net pipeline (scale=True, alpha=1.0, l1_ratio=0.5).

--- Running Nested CV for Regression: Random Forest (rf) ---
Output directory: /home/cseomoon/appl/af_analysis-0.1.4/model/regression/results/rg_main_20250425_155240/rf
Hyperparameter tuning scoring metric: neg_mean_squared_error
Using GroupKFold for outer CV with 5 folds based on query IDs.

-- Processing Outer Fold 1/5 --
Train set size: (2898, 63), Test set size: (749, 63)
Test set indices range from 100 to 3496
Using GroupKFold for inner CV with 3 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 3 folds for each of 100 candidates, totalling 300 fits
