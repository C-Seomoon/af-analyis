=============================================
[INFO] Job Information
---------------------------------------------
[INFO] Job Name       : cls_framework
[INFO] Job ID         : 179773
[INFO] Submit Dir     : /home/cseomoon/appl/af_analysis-0.1.4/model/classification/scripts
[INFO] Partition      : g4090_short
[INFO] Node List      : gpu10
[INFO] Nodes          : 1
[INFO] CPUs per Task  : 32
[INFO] Memory (MB)    : 
[INFO] User           : cseomoon
[INFO] Work Dir       : /home/cseomoon/appl/af_analysis-0.1.4/model/classification/scripts
[INFO] Tasks per Node : 1
[INFO] Dependency     : 
[INFO] GPU(s)         : 
=============================================

[INFO] Job started at : Wed Apr 23 19:13:10 KST 2025
[INFO] Job allocated on node(s): gpu10
[INFO] Job running on: gpu10
Using 32 CPU cores.
Results will be saved to: ../results/cls_test
Results saved to ../results/cls_test/run_arguments.json

--- Loading Data ---
Original data shape: (3650, 81)
Class distribution (DockQ >= 0.23): 0 (Negative) = 2529, 1 (Positive) = 1121
Columns to drop for features (X): ['seed', 'iRMS', 'chain_iptm', 'format', 'LRMS', 'model_path', 'native_path', 'chain_pair_pae_min', 'Fnonnat', 'DockQ', 'query', 'chain_pair_iptm', 'Fnat', 'pdb', 'sample', 'rRMS', 'chain_ptm', 'data_file']
Processed Features (X) shape: (3650, 63)
Processed Target (y) shape: (3650,)
Processed Query IDs shape: (3650,)
Data Loading & Preprocessing Duration: 0.04 seconds

--- Starting Model Training ---

--- Running Nested CV for: Random Forest (rf) ---
Output directory: ../results/cls_test/rf
Using GroupKFold for outer CV with 2 folds based on query IDs.

-- Processing Outer Fold 1/2 --
Train set size: (1800, 63), Test set size: (1850, 63)
Test set indices range from 0 to 3499
Using GroupKFold for inner CV with 2 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 2 folds for each of 50 candidates, totalling 100 fits
Best Params found: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None, 'class_weight': 'balanced'}
Best Inner CV ROC AUC score: 0.9178
Results saved to ../results/cls_test/rf/fold_1/best_params.json
Hyperparameter Tuning Duration: 12.30 seconds
Predicting on outer test set...
Calculating performance metrics...
Results saved to ../results/cls_test/rf/fold_1/metrics.json
Predictions saved to ../results/cls_test/rf/fold_1/predictions.csv
Prediction & Evaluation Duration: 0.20 seconds
Calculating and saving SHAP values...
Calculating SHAP values using TreeExplainer for RandomForest...
SHAP explainer returned a 3D ndarray. Returning values for the positive class (index 1).
SHAP values saved to ../results/cls_test/rf/fold_1/shap_values_fold_1.csv (shape: (1850, 63))
Test data corresponding to SHAP values saved to ../results/cls_test/rf/fold_1/test_data_fold_1.csv (shape: (1850, 63))
SHAP Calculation & Saving Duration: 4.26 seconds
-- Outer Fold 1 finished. Duration: 16.76 seconds --

-- Processing Outer Fold 2/2 --
Train set size: (1850, 63), Test set size: (1800, 63)
Test set indices range from 50 to 3649
Using GroupKFold for inner CV with 2 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 2 folds for each of 50 candidates, totalling 100 fits
Best Params found: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 40, 'class_weight': None}
Best Inner CV ROC AUC score: 0.9571
Results saved to ../results/cls_test/rf/fold_2/best_params.json
Hyperparameter Tuning Duration: 8.75 seconds
Predicting on outer test set...
Calculating performance metrics...
Results saved to ../results/cls_test/rf/fold_2/metrics.json
Predictions saved to ../results/cls_test/rf/fold_2/predictions.csv
Prediction & Evaluation Duration: 0.14 seconds
Calculating and saving SHAP values...
Calculating SHAP values using TreeExplainer for RandomForest...
SHAP explainer returned a 3D ndarray. Returning values for the positive class (index 1).
SHAP values saved to ../results/cls_test/rf/fold_2/shap_values_fold_2.csv (shape: (1800, 63))
Test data corresponding to SHAP values saved to ../results/cls_test/rf/fold_2/test_data_fold_2.csv (shape: (1800, 63))
SHAP Calculation & Saving Duration: 2.15 seconds
-- Outer Fold 2 finished. Duration: 11.09 seconds --

--- Aggregating results for: Random Forest (rf) ---
Average Metrics across folds:
{
    "accuracy_mean": 0.8840315315315315,
    "accuracy_std": 0.02569819819819824,
    "precision_mean": 0.8240430783796577,
    "precision_std": 0.041785013863528786,
    "recall_mean": 0.8109396415899164,
    "recall_std": 0.12716480715283024,
    "f1_mean": 0.8086147797936208,
    "f1_std": 0.04450747174551728,
    "roc_auc_mean": 0.9403314114488173,
    "roc_auc_std": 0.018408998992284376,
    "pr_auc_mean": 0.9011985337885717,
    "pr_auc_std": 0.020588104891100245,
    "balanced_accuracy_mean": 0.8667730646661267,
    "balanced_accuracy_std": 0.05164150029039294,
    "mcc_mean": 0.7349184589200014,
    "mcc_std": 0.060597204747929956,
    "best_inner_cv_roc_auc_mean": 0.9374143015122154,
    "best_inner_cv_roc_auc_std": 0.01965022995256782
}
Results saved to ../results/cls_test/rf/metrics_summary.json

Running global SHAP analysis...

--- Starting Global SHAP Analysis in: ../results/cls_test/rf ---
Searching for 'shap_values_fold_*.csv' in subdirectories of ../results/cls_test/rf...
Found 2 SHAP files: ['shap_values_fold_1.csv', 'shap_values_fold_2.csv']
Searching for 'test_data_fold_*.csv' in subdirectories of ../results/cls_test/rf...
Found 2 test data files: ['test_data_fold_1.csv', 'test_data_fold_2.csv']
Found matching SHAP and test data for folds: [1, 2]

Loading Fold 1:
  SHAP file: ../results/cls_test/rf/fold_1/shap_values_fold_1.csv
  Test data file: ../results/cls_test/rf/fold_1/test_data_fold_1.csv
  Loaded SHAP shape: (1850, 63)
  Loaded Test Data shape: (1850, 63)
  Established feature names from Fold 1 (63 features).

Loading Fold 2:
  SHAP file: ../results/cls_test/rf/fold_2/shap_values_fold_2.csv
  Test data file: ../results/cls_test/rf/fold_2/test_data_fold_2.csv
  Loaded SHAP shape: (1800, 63)
  Loaded Test Data shape: (1800, 63)

Combining data from 2 folds...
Successfully combined data from 2 folds.
Combined SHAP values shape: (3650, 63)
Combined test data shape: (3650, 63)

Generating global SHAP plots in: ../results/cls_test/rf/global_shap_analysis
Global SHAP bar plot saved to: ../results/cls_test/rf/global_shap_analysis/rf_global_shap_bar.png
Global SHAP dot plot saved to: ../results/cls_test/rf/global_shap_analysis/rf_global_shap_beeswarm.png
--- Global SHAP Analysis Finished for: rf ---
Global SHAP Analysis Duration: 3.19 seconds
Result Aggregation & Global SHAP Duration: 3.21 seconds
Average time per outer fold: 13.92 seconds
--- Nested CV completed for: Random Forest (rf) ---
Total execution time for model 'rf': 31.07 seconds

--- Running Nested CV for: XGBoost (xgb) ---
Output directory: ../results/cls_test/xgb
Using GroupKFold for outer CV with 2 folds based on query IDs.

-- Processing Outer Fold 1/2 --
Train set size: (1800, 63), Test set size: (1850, 63)
Test set indices range from 0 to 3499
Using GroupKFold for inner CV with 2 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 2 folds for each of 50 candidates, totalling 100 fits
Best Params found: {'subsample': 0.8, 'scale_pos_weight': 1, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.6}
Best Inner CV ROC AUC score: 0.9095
Results saved to ../results/cls_test/xgb/fold_1/best_params.json
Hyperparameter Tuning Duration: 4.83 seconds
Predicting on outer test set...
Calculating performance metrics...
Results saved to ../results/cls_test/xgb/fold_1/metrics.json
Predictions saved to ../results/cls_test/xgb/fold_1/predictions.csv
Prediction & Evaluation Duration: 0.14 seconds
Calculating and saving SHAP values...
Calculating SHAP values using TreeExplainer for XGBoost...
Returning SHAP values (expected for positive class log-odds).
SHAP values saved to ../results/cls_test/xgb/fold_1/shap_values_fold_1.csv (shape: (1850, 63))
Test data corresponding to SHAP values saved to ../results/cls_test/xgb/fold_1/test_data_fold_1.csv (shape: (1850, 63))
SHAP Calculation & Saving Duration: 0.45 seconds
-- Outer Fold 1 finished. Duration: 5.43 seconds --

-- Processing Outer Fold 2/2 --
Train set size: (1850, 63), Test set size: (1800, 63)
Test set indices range from 50 to 3649
Using GroupKFold for inner CV with 2 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 2 folds for each of 50 candidates, totalling 100 fits
Best Params found: {'subsample': 0.8, 'scale_pos_weight': 5, 'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.1, 'gamma': 0.5, 'colsample_bytree': 0.6}
Best Inner CV ROC AUC score: 0.9461
Results saved to ../results/cls_test/xgb/fold_2/best_params.json
Hyperparameter Tuning Duration: 2.12 seconds
Predicting on outer test set...
Calculating performance metrics...
Results saved to ../results/cls_test/xgb/fold_2/metrics.json
Predictions saved to ../results/cls_test/xgb/fold_2/predictions.csv
Prediction & Evaluation Duration: 0.78 seconds
Calculating and saving SHAP values...
Calculating SHAP values using TreeExplainer for XGBoost...
Returning SHAP values (expected for positive class log-odds).
SHAP values saved to ../results/cls_test/xgb/fold_2/shap_values_fold_2.csv (shape: (1800, 63))
Test data corresponding to SHAP values saved to ../results/cls_test/xgb/fold_2/test_data_fold_2.csv (shape: (1800, 63))
SHAP Calculation & Saving Duration: 0.41 seconds
-- Outer Fold 2 finished. Duration: 3.31 seconds --

--- Aggregating results for: XGBoost (xgb) ---
Average Metrics across folds:
{
    "accuracy_mean": 0.8788513513513514,
    "accuracy_std": 0.023851351351351354,
    "precision_mean": 0.809900490220029,
    "precision_std": 0.04370775720265141,
    "recall_mean": 0.8117674561594528,
    "recall_std": 0.12633699258329384,
    "f1_mean": 0.801904419690981,
    "f1_std": 0.04157384117858426,
    "roc_auc_mean": 0.9369083621359502,
    "roc_auc_std": 0.019514012316463658,
    "pr_auc_mean": 0.8972197401928295,
    "pr_auc_std": 0.021717914930329818,
    "balanced_accuracy_mean": 0.8632856517211718,
    "balanced_accuracy_std": 0.050252694180584034,
    "mcc_mean": 0.7242875090566587,
    "mcc_std": 0.05798664946696469,
    "best_inner_cv_roc_auc_mean": 0.9278163090990069,
    "best_inner_cv_roc_auc_std": 0.01831698672274218
}
Results saved to ../results/cls_test/xgb/metrics_summary.json

Running global SHAP analysis...

--- Starting Global SHAP Analysis in: ../results/cls_test/xgb ---
Searching for 'shap_values_fold_*.csv' in subdirectories of ../results/cls_test/xgb...
Found 2 SHAP files: ['shap_values_fold_1.csv', 'shap_values_fold_2.csv']
Searching for 'test_data_fold_*.csv' in subdirectories of ../results/cls_test/xgb...
Found 2 test data files: ['test_data_fold_1.csv', 'test_data_fold_2.csv']
Found matching SHAP and test data for folds: [1, 2]

Loading Fold 1:
  SHAP file: ../results/cls_test/xgb/fold_1/shap_values_fold_1.csv
  Test data file: ../results/cls_test/xgb/fold_1/test_data_fold_1.csv
  Loaded SHAP shape: (1850, 63)
  Loaded Test Data shape: (1850, 63)
  Established feature names from Fold 1 (63 features).

Loading Fold 2:
  SHAP file: ../results/cls_test/xgb/fold_2/shap_values_fold_2.csv
  Test data file: ../results/cls_test/xgb/fold_2/test_data_fold_2.csv
  Loaded SHAP shape: (1800, 63)
  Loaded Test Data shape: (1800, 63)

Combining data from 2 folds...
Successfully combined data from 2 folds.
Combined SHAP values shape: (3650, 63)
Combined test data shape: (3650, 63)

Generating global SHAP plots in: ../results/cls_test/xgb/global_shap_analysis
Global SHAP bar plot saved to: ../results/cls_test/xgb/global_shap_analysis/xgb_global_shap_bar.png
Global SHAP dot plot saved to: ../results/cls_test/xgb/global_shap_analysis/xgb_global_shap_beeswarm.png
--- Global SHAP Analysis Finished for: xgb ---
Global SHAP Analysis Duration: 3.14 seconds
Result Aggregation & Global SHAP Duration: 3.22 seconds
Average time per outer fold: 4.37 seconds
--- Nested CV completed for: XGBoost (xgb) ---
Total execution time for model 'xgb': 11.99 seconds

--- Running Nested CV for: LightGBM (lgb) ---
Output directory: ../results/cls_test/lgb
Using GroupKFold for outer CV with 2 folds based on query IDs.

-- Processing Outer Fold 1/2 --
Train set size: (1800, 63), Test set size: (1850, 63)
Test set indices range from 0 to 3499
Using GroupKFold for inner CV with 2 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 2 folds for each of 50 candidates, totalling 100 fits
Best Params found: {'subsample': 0.8, 'reg_lambda': 0, 'reg_alpha': 0.01, 'num_leaves': 60, 'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.05, 'colsample_bytree': 0.8, 'class_weight': None}
Best Inner CV ROC AUC score: 0.9130
Results saved to ../results/cls_test/lgb/fold_1/best_params.json
Hyperparameter Tuning Duration: 81.52 seconds
Predicting on outer test set...
Calculating performance metrics...
Results saved to ../results/cls_test/lgb/fold_1/metrics.json
Predictions saved to ../results/cls_test/lgb/fold_1/predictions.csv
Prediction & Evaluation Duration: 0.41 seconds
Calculating and saving SHAP values...
Calculating SHAP values using TreeExplainer for LightGBM...
SHAP explainer returned a single array. Returning as is.
SHAP values saved to ../results/cls_test/lgb/fold_1/shap_values_fold_1.csv (shape: (1850, 63))
Test data corresponding to SHAP values saved to ../results/cls_test/lgb/fold_1/test_data_fold_1.csv (shape: (1850, 63))
SHAP Calculation & Saving Duration: 0.91 seconds
-- Outer Fold 1 finished. Duration: 82.84 seconds --

-- Processing Outer Fold 2/2 --
Train set size: (1850, 63), Test set size: (1800, 63)
Test set indices range from 50 to 3649
Using GroupKFold for inner CV with 2 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 2 folds for each of 50 candidates, totalling 100 fits
Best Params found: {'subsample': 0.8, 'reg_lambda': 5, 'reg_alpha': 0.01, 'num_leaves': 50, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.6, 'class_weight': None}
Best Inner CV ROC AUC score: 0.9586
Results saved to ../results/cls_test/lgb/fold_2/best_params.json
Hyperparameter Tuning Duration: 109.97 seconds
Predicting on outer test set...
Calculating performance metrics...
Results saved to ../results/cls_test/lgb/fold_2/metrics.json
Predictions saved to ../results/cls_test/lgb/fold_2/predictions.csv
Prediction & Evaluation Duration: 0.11 seconds
Calculating and saving SHAP values...
Calculating SHAP values using TreeExplainer for LightGBM...
SHAP explainer returned a single array. Returning as is.
SHAP values saved to ../results/cls_test/lgb/fold_2/shap_values_fold_2.csv (shape: (1800, 63))
Test data corresponding to SHAP values saved to ../results/cls_test/lgb/fold_2/test_data_fold_2.csv (shape: (1800, 63))
SHAP Calculation & Saving Duration: 0.62 seconds
-- Outer Fold 2 finished. Duration: 110.70 seconds --

--- Aggregating results for: LightGBM (lgb) ---
Average Metrics across folds:
{
    "accuracy_mean": 0.8777702702702703,
    "accuracy_std": 0.02277027027027029,
    "precision_mean": 0.81357603566074,
    "precision_std": 0.05054286030528976,
    "recall_mean": 0.8040385181959087,
    "recall_std": 0.1301974585932596,
    "f1_mean": 0.7986046511627907,
    "f1_std": 0.0413953488372093,
    "roc_auc_mean": 0.9394073034208088,
    "roc_auc_std": 0.03135424576726181,
    "pr_auc_mean": 0.9069615079035886,
    "pr_auc_std": 0.04157845952264738,
    "balanced_accuracy_mean": 0.8605092996682976,
    "balanced_accuracy_std": 0.05034462270978246,
    "mcc_mean": 0.7217968880818033,
    "mcc_std": 0.05539925246860056,
    "best_inner_cv_roc_auc_mean": 0.9357888735214903,
    "best_inner_cv_roc_auc_std": 0.022815578904382794
}
Results saved to ../results/cls_test/lgb/metrics_summary.json

Running global SHAP analysis...

--- Starting Global SHAP Analysis in: ../results/cls_test/lgb ---
Searching for 'shap_values_fold_*.csv' in subdirectories of ../results/cls_test/lgb...
Found 2 SHAP files: ['shap_values_fold_1.csv', 'shap_values_fold_2.csv']
Searching for 'test_data_fold_*.csv' in subdirectories of ../results/cls_test/lgb...
Found 2 test data files: ['test_data_fold_1.csv', 'test_data_fold_2.csv']
Found matching SHAP and test data for folds: [1, 2]

Loading Fold 1:
  SHAP file: ../results/cls_test/lgb/fold_1/shap_values_fold_1.csv
  Test data file: ../results/cls_test/lgb/fold_1/test_data_fold_1.csv
  Loaded SHAP shape: (1850, 63)
  Loaded Test Data shape: (1850, 63)
  Established feature names from Fold 1 (63 features).

Loading Fold 2:
  SHAP file: ../results/cls_test/lgb/fold_2/shap_values_fold_2.csv
  Test data file: ../results/cls_test/lgb/fold_2/test_data_fold_2.csv
  Loaded SHAP shape: (1800, 63)
  Loaded Test Data shape: (1800, 63)

Combining data from 2 folds...
Successfully combined data from 2 folds.
Combined SHAP values shape: (3650, 63)
Combined test data shape: (3650, 63)

Generating global SHAP plots in: ../results/cls_test/lgb/global_shap_analysis
Global SHAP bar plot saved to: ../results/cls_test/lgb/global_shap_analysis/lgb_global_shap_bar.png
Global SHAP dot plot saved to: ../results/cls_test/lgb/global_shap_analysis/lgb_global_shap_beeswarm.png
--- Global SHAP Analysis Finished for: lgb ---
Global SHAP Analysis Duration: 3.51 seconds
Result Aggregation & Global SHAP Duration: 3.59 seconds
Average time per outer fold: 96.77 seconds
--- Nested CV completed for: LightGBM (lgb) ---
Total execution time for model 'lgb': 197.14 seconds

--- Running Nested CV for: Logistic Regression (logistic) ---
Output directory: ../results/cls_test/logistic
Using GroupKFold for outer CV with 2 folds based on query IDs.

-- Processing Outer Fold 1/2 --
Train set size: (1800, 63), Test set size: (1850, 63)
Test set indices range from 0 to 3499
Using GroupKFold for inner CV with 2 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 2 folds for each of 50 candidates, totalling 100 fits
Best Params found: {'model__solver': 'saga', 'model__penalty': 'elasticnet', 'model__l1_ratio': 0.2, 'model__C': 0.000774263682681127}
Best Inner CV ROC AUC score: 0.9066
Results saved to ../results/cls_test/logistic/fold_1/best_params.json
Hyperparameter Tuning Duration: 4.03 seconds
Predicting on outer test set...
Error during prediction or evaluation in fold 1: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/home/cseomoon/appl/af_analysis-0.1.4/model/classification/train_models.py", line 145, in run_nested_cv
    y_prob = best_estimator.predict_proba(X_test)[:, 1] # Probability of class 1
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/pipeline.py", line 904, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1428, in predict_proba
    return super()._predict_proba_lr(X)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 389, in _predict_proba_lr
    prob = self.decision_function(X)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 351, in decision_function
    X = validate_data(self, X, accept_sparse="csr", reset=False)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2944, in validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Prediction & Evaluation (Error) Duration: 0.04 seconds

-- Processing Outer Fold 2/2 --
Train set size: (1850, 63), Test set size: (1800, 63)
Test set indices range from 50 to 3649
Using GroupKFold for inner CV with 2 folds.
Starting hyperparameter tuning (RandomizedSearchCV)...
Fitting 2 folds for each of 50 candidates, totalling 100 fits
Error during RandomizedSearchCV in fold 2: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/home/cseomoon/appl/af_analysis-0.1.4/model/classification/train_models.py", line 119, in run_nested_cv
    search.fit(X_train, y_train) # Fit on the outer training data
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1062, in fit
    self.best_estimator_.fit(X, y, **routed_params.estimator.fit)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/pipeline.py", line 662, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1222, in fit
    X, y = validate_data(
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/cseomoon/miniconda3/envs/Abnb/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Hyperparameter Tuning (Error) Duration: 1.10 seconds

Error: No metrics were collected for model logistic. Check logs for errors in folds.
Total execution time for model 'logistic': 5.26 seconds

--- Overall Training Summary ---
Model comparison summary saved to: ../results/cls_test/model_comparison_summary.csv
  model_name  accuracy_mean  ...  best_inner_cv_roc_auc_std                 error
0         rf       0.884032  ...                   0.019650                   NaN
1        xgb       0.878851  ...                   0.018317                   NaN
2        lgb       0.877770  ...                   0.022816                   NaN
3   logistic            NaN  ...                        NaN  No metrics collected

[4 rows x 20 columns]
Final Summary Saving Duration: 0.06 seconds

--- Framework Execution Finished ---
Total script execution time: 245.64 seconds
작업 완료
[INFO] Job completed at: Wed Apr 23 19:17:29 KST 2025
