{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b397a91-8bfe-491c-a27c-d33cb4568fa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T10:13:51.633784Z",
     "iopub.status.busy": "2025-05-22T10:13:51.633419Z",
     "iopub.status.idle": "2025-05-22T10:13:58.071017Z",
     "shell.execute_reply": "2025-05-22T10:13:58.069945Z",
     "shell.execute_reply.started": "2025-05-22T10:13:51.633739Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import af_analysis\n",
    "import time\n",
    "from Bio.PDB import MMCIFParser, PDBIO\n",
    "\n",
    "def convert_cif_to_pdb(cif_path):\n",
    "    try:\n",
    "        pdb_path = os.path.splitext(cif_path)[0] + '.pdb'\n",
    "        if os.path.exists(pdb_path):\n",
    "            return pdb_path\n",
    "        parser = MMCIFParser()\n",
    "        structure = parser.get_structure('structure', cif_path)\n",
    "        io = PDBIO()\n",
    "        io.set_structure(structure)\n",
    "        io.save(pdb_path)\n",
    "        print(f\"Converted {cif_path} to {pdb_path}\")\n",
    "        return pdb_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {cif_path} to PDB: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_model(file_path):\n",
    "    try:\n",
    "        if file_path.endswith('.cif'):\n",
    "            pdb_path = convert_cif_to_pdb(file_path)\n",
    "            if not pdb_path:\n",
    "                return file_path, np.nan, \"CIF to PDB conversion failed\"\n",
    "            model_path = pdb_path\n",
    "        else:\n",
    "            model_path = file_path\n",
    "\n",
    "        model_dir = os.path.dirname(os.path.dirname(model_path))\n",
    "        temp_data = af_analysis.data.Data(directory=model_dir)\n",
    "\n",
    "        temp_data.df = pd.DataFrame({\n",
    "            'model_path': [model_path],\n",
    "            'pdb': [os.path.basename(model_dir)]\n",
    "        })\n",
    "\n",
    "        temp_data.calculate_binding_energy(n_jobs=1, verbose=False)\n",
    "\n",
    "        if 'del_G_B' in temp_data.df.columns and not pd.isna(temp_data.df.loc[0, 'del_G_B']):\n",
    "            return model_path, temp_data.df.loc[0, 'del_G_B'], None\n",
    "        else:\n",
    "            return model_path, np.nan, \"Energy calculation failed\"\n",
    "    except Exception as e:\n",
    "        return file_path, np.nan, str(e)\n",
    "\n",
    "def run_rosetta_energy_calculation(csv_file, node_id=0, total_nodes=1):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(f\"Loaded {len(df)} rows from {csv_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    if 'del_G_B' not in df.columns:\n",
    "        df['del_G_B'] = np.nan\n",
    "\n",
    "    if 'model_path' in df.columns:\n",
    "        path_column = 'model_path'\n",
    "    elif 'pdb' in df.columns:\n",
    "        path_column = 'pdb'\n",
    "    else:\n",
    "        print(\"Error: No path column found\")\n",
    "        return None\n",
    "\n",
    "    valid_paths = df[pd.notna(df[path_column])][path_column].tolist()\n",
    "    files_to_process = [path for path in valid_paths if os.path.exists(path)]\n",
    "    print(f\"Found {len(files_to_process)} valid file paths\")\n",
    "\n",
    "    files_per_node = [files_to_process[i::total_nodes] for i in range(total_nodes)]\n",
    "    my_files = files_per_node[node_id]\n",
    "    print(f\"Node {node_id} processing {len(my_files)} files\")\n",
    "\n",
    "    files_to_calculate = []\n",
    "    for file_path in my_files:\n",
    "        idx = df[df[path_column] == file_path].index\n",
    "        if len(idx) > 0 and pd.isna(df.loc[idx[0], 'del_G_B']):\n",
    "            files_to_calculate.append(file_path)\n",
    "\n",
    "    print(f\"Need to calculate {len(files_to_calculate)} files\")\n",
    "\n",
    "    if not files_to_calculate:\n",
    "        print(\"No files to process.\")\n",
    "        return df\n",
    "\n",
    "    num_cores = max(1, mp.cpu_count() - 2)\n",
    "    print(f\"Using {num_cores} CPU cores\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = []\n",
    "    errors = []\n",
    "\n",
    "    with mp.Pool(processes=num_cores) as pool:\n",
    "        for file_path, energy, error in tqdm(\n",
    "            pool.imap_unordered(process_model, files_to_calculate),\n",
    "            total=len(files_to_calculate),\n",
    "            desc=\"Calculating binding energy\"\n",
    "        ):\n",
    "            idx = df[df[path_column] == file_path].index\n",
    "            if len(idx) > 0:\n",
    "                df.loc[idx[0], 'del_G_B'] = energy\n",
    "\n",
    "            if error:\n",
    "                errors.append(f\"{file_path}: {error}\")\n",
    "            else:\n",
    "                results.append(file_path)\n",
    "\n",
    "    print(f\"Success: {len(results)} / {len(files_to_calculate)}\")\n",
    "    if errors:\n",
    "        print(\"Errors (top 5):\")\n",
    "        for msg in errors[:5]:\n",
    "            print(f\"  {msg}\")\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Completed in {elapsed:.2f} seconds\")\n",
    "    \n",
    "    return df  # 결과를 Jupyter에서 확인할 수 있도록 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349ab042-315d-4e58-95ec-501810c4c047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T10:14:36.339046Z",
     "iopub.status.busy": "2025-05-22T10:14:36.338351Z",
     "iopub.status.idle": "2025-05-22T10:14:40.517665Z",
     "shell.execute_reply": "2025-05-22T10:14:40.516738Z",
     "shell.execute_reply.started": "2025-05-22T10:14:36.339002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3650 rows from /home/cseomoon/appl/af_analysis-0.1.4/data/sequence_classification/train_set_AbNb/native/AbNb_final_h3_l3_plddt_20250522.csv\n",
      "Found 3650 valid file paths\n",
      "Node 0 processing 3650 files\n",
      "Need to calculate 0 files\n",
      "No files to process.\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/home/cseomoon/appl/af_analysis-0.1.4/data/sequence_classification/train_set_AbNb/native/AbNb_final_h3_l3_plddt_20250522.csv\"\n",
    "node_id = 0\n",
    "total_nodes = 1\n",
    "\n",
    "# 실행\n",
    "result_df = run_rosetta_energy_calculation(csv_path, node_id=node_id, total_nodes=total_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059b2c6-bdfc-4811-9c80-1b5c65aca88b",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd                                                                                                                                                                                             \n",
    " import glob                                                                                                                                                                                                     \n",
    " import os                                                                                                                                                                                                       \n",
    "                                                                                                                                                                                                                 \n",
    " # 결과 파일 찾기                                                                                                                                                                                                \n",
    " result_files = glob.glob(\"/home/cseomoon/appl/af_analysis-0.1.4/results/energy_calc/energy_result_*.csv\")                                                                                                                                                   \n",
    " print(f\"Found {len(result_files)} result files to merge\")                                                                                                                                                       \n",
    "                                                                                                                                                                                                                 \n",
    " if not result_files:                                                                                                                                                                                            \n",
    "     print(\"No result files found!\")                                                                                                                                                                             \n",
    "     exit(1)                                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                                 \n",
    " # 모든 결과 읽어서 하나로 합치기                                                                                                                                                                                \n",
    " dfs = []                                                                                                                                                                                                        \n",
    " for f in result_files:                                                                                                                                                                                          \n",
    "     try:                                                                                                                                                                                                        \n",
    "         df = pd.read_csv(f)                                                                                                                                                                                     \n",
    "         dfs.append(df)                                                                                                                                                                                          \n",
    "         print(f\"Loaded {f}: {len(df)} rows\")                                                                                                                                                                    \n",
    "     except Exception as e:                                                                                                                                                                                      \n",
    "         print(f\"Error loading {f}: {e}\")                                                                                                                                                                        \n",
    "                                                                                                                                                                                                                 \n",
    " if not dfs:                                                                                                                                                                                                     \n",
    "     print(\"No valid data frames to merge!\")                                                                                                                                                                     \n",
    "     exit(1)                                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                                 \n",
    " # 합치기                                                                                                                                                                                                        \n",
    " all_results = pd.concat(dfs)                                                                                                                                                                                    \n",
    " print(f\"Combined data frame has {len(all_results)} rows\")                                                                                                                                                       \n",
    "                                                                                                                                                                                                                 \n",
    " # 합친 결과 저장                                                                                                                                                                                                \n",
    " all_results.to_csv(\"${FINAL_OUTPUT}\", index=False)                                                                                                                                                              \n",
    " print(f\"Results saved to ${FINAL_OUTPUT}\")                                                                                                                                                                      \n",
    " EOF                                                                                                                                                                                                             \n",
    "                                                                                                                                                                                                                 \n",
    " echo \"Merge completed\"  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Abnb)",
   "language": "python",
   "name": "abnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
