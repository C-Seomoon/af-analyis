{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced22f6d-e28b-4e57-856c-943a268953d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T08:58:01.452548Z",
     "iopub.status.busy": "2025-05-26T08:58:01.452243Z",
     "iopub.status.idle": "2025-05-26T08:58:01.462066Z",
     "shell.execute_reply": "2025-05-26T08:58:01.461255Z",
     "shell.execute_reply.started": "2025-05-26T08:58:01.452516Z"
    }
   },
   "outputs": [],
   "source": [
    "# import af_analysis\n",
    "# from af_analysis import analysis\n",
    "# from af_analysis.data import Data\n",
    "\n",
    "# def calculate_all_metrics_per_query(query_group_data, **kwargs):\n",
    "#     \"\"\"\n",
    "#     ë‹¨ì¼ query ê·¸ë£¹ì— ëŒ€í•´ ëª¨ë“  ë©”íŠ¸ë¦­ì„ ìˆœì°¨ì ìœ¼ë¡œ ê³„ì‚°\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     query_group_data : tuple\n",
    "#         (query_name, query_df) í˜•íƒœì˜ ë°ì´í„°\n",
    "#     kwargs : dict\n",
    "#         ê°ì¢… ë©”íŠ¸ë¦­ ê³„ì‚° ì˜µì…˜ë“¤\n",
    "        \n",
    "#     Returns\n",
    "#     -------\n",
    "#     result_df : pd.DataFrame\n",
    "#         ëª¨ë“  ë©”íŠ¸ë¦­ì´ ê³„ì‚°ëœ query ë°ì´í„°\n",
    "#     \"\"\"\n",
    "#     query_name, query_df = query_group_data\n",
    "    \n",
    "#     try:\n",
    "#         # # Data ê°ì²´ ìƒì„±\n",
    "#         temp_data = Data(data_dict={\n",
    "#             'pdb': query_df['pdb'].tolist(),\n",
    "#             'query': query_df['query'].tolist(),\n",
    "#             'data_file': query_df['data_file'].tolist()\n",
    "#             # ... ê¸°íƒ€ í•„ìš”í•œ ì»¬ëŸ¼ë“¤\n",
    "#         })\n",
    "        \n",
    "#         # # ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚° (ìˆœì°¨ ì‹¤í–‰)\n",
    "#         # temp_data = (temp_data\n",
    "#         #             .extract_chain_columns(verbose=False)\n",
    "#         #             .analyze_chains(verbose=False))\n",
    "        \n",
    "#         # # Analysis í•¨ìˆ˜ë“¤\n",
    "#         # from af_analysis import analysis\n",
    "#         # analysis.add_interface_metrics(temp_data, verbose=False)\n",
    "#         # analysis.pdockq(temp_data, verbose=False)\n",
    "#         # analysis.pdockq2(temp_data, verbose=False)\n",
    "        \n",
    "#         # # Data ë©”ì„œë“œë“¤\n",
    "#         # temp_data = (temp_data\n",
    "#         #             .add_pitm_pis(cutoff=8.0, verbose=False)\n",
    "#         #             .add_chain_rmsd(align_chain='A', rmsd_chain='H')\n",
    "#         #             .add_rmsd_scale())\n",
    "        \n",
    "#         # Rosetta ë©”íŠ¸ë¦­ (multiprocessing ë¹„í™œì„±í™”)\n",
    "#         temp_data = (temp_data.add_rosetta_metrics(n_jobs=1, verbose=False))\n",
    "        \n",
    "#         # DockQ (ì˜µì…˜)\n",
    "#         if kwargs.get('calculate_dockq', False):\n",
    "#             temp_data.prep_dockq(native_dir=kwargs.get('native_dir'), verbose=False)\n",
    "#             analysis.calculate_dockQ(temp_data, \n",
    "#                                    rec_chains='A', lig_chains='H',\n",
    "#                                    native_rec_chains='A', native_lig_chains='H',\n",
    "#                                    verbose=False)\n",
    "        \n",
    "#         return query_name, temp_data.df\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing query {query_name}: {str(e)}\")\n",
    "#         return query_name, None\n",
    "\n",
    "\n",
    "# def calculate_all_metrics_parallel(data_obj, n_jobs=None, **kwargs):\n",
    "#     \"\"\"\n",
    "#     ëª¨ë“  queryì— ëŒ€í•´ ë³‘ë ¬ë¡œ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data_obj : Data\n",
    "#         ì „ì²´ ë°ì´í„° ê°ì²´\n",
    "#     n_jobs : int, optional\n",
    "#         ì‚¬ìš©í•  CPU ì½”ì–´ ìˆ˜. Noneì´ë©´ ìë™ ì„¤ì •\n",
    "#     **kwargs : dict\n",
    "#         ë©”íŠ¸ë¦­ ê³„ì‚° ì˜µì…˜ë“¤\n",
    "        \n",
    "#     Returns\n",
    "#     -------\n",
    "#     updated_data : Data\n",
    "#         ëª¨ë“  ë©”íŠ¸ë¦­ì´ ê³„ì‚°ëœ ë°ì´í„° ê°ì²´\n",
    "#     \"\"\"\n",
    "#     import multiprocessing as mp\n",
    "#     from functools import partial\n",
    "#     import pandas as pd\n",
    "#     from tqdm.auto import tqdm\n",
    "    \n",
    "#     # Queryë³„ë¡œ ë°ì´í„° ê·¸ë£¹í™”\n",
    "#     query_groups = list(data_obj.df.groupby('query'))\n",
    "    \n",
    "#     if n_jobs is None:\n",
    "#         n_jobs = min(mp.cpu_count(), len(query_groups))\n",
    "    \n",
    "#     print(f\"Processing {len(query_groups)} queries using {n_jobs} CPU cores...\")\n",
    "    \n",
    "#     # ë³‘ë ¬ ì²˜ë¦¬\n",
    "#     worker_func = partial(calculate_all_metrics_per_query, **kwargs)\n",
    "    \n",
    "#     if n_jobs > 1:\n",
    "#         ctx = mp.get_context(\"fork\")\n",
    "#         with ctx.Pool(n_jobs) as pool:\n",
    "#             results = list(tqdm(\n",
    "#                 pool.imap(worker_func, query_groups),\n",
    "#                 total=len(query_groups),\n",
    "#                 desc=\"Processing queries\"\n",
    "#             ))\n",
    "#     else:\n",
    "#         results = [worker_func(group) for group in tqdm(query_groups, desc=\"Processing queries\")]\n",
    "    \n",
    "#     # ê²°ê³¼ í†µí•©\n",
    "#     successful_results = []\n",
    "#     failed_queries = []\n",
    "    \n",
    "#     for query_name, result_df in results:\n",
    "#         if result_df is not None:\n",
    "#             successful_results.append(result_df)\n",
    "#         else:\n",
    "#             failed_queries.append(query_name)\n",
    "    \n",
    "#     if failed_queries:\n",
    "#         print(f\"Failed to process {len(failed_queries)} queries: {failed_queries}\")\n",
    "    \n",
    "#     # DataFrame í†µí•©\n",
    "#     if successful_results:\n",
    "#         combined_df = pd.concat(successful_results, ignore_index=True)\n",
    "#         data_obj.df = combined_df\n",
    "#         print(f\"Successfully processed {len(successful_results)} queries\")\n",
    "    \n",
    "#     return data_obj\n",
    "\n",
    "\n",
    "# # ì‚¬ìš© ì˜ˆì‹œ\n",
    "# def main():\n",
    "#     # ë°ì´í„° ë¡œë“œ\n",
    "#     input_data=Data(directory='/home/cseomoon/project/ABAG/2025_H_L_A/20250504_seeds_10/negative/af3_results/results1/6x97_7o9w')\n",
    "#     # my_data.df\n",
    "#     # data = Data(csv=\"your_data.csv\")\n",
    "    \n",
    "#     # ë³‘ë ¬ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "#     my_data = calculate_all_metrics_parallel(\n",
    "#         input_data, \n",
    "#         n_jobs=48,  # 8 CPU ì½”ì–´ ì‚¬ìš©\n",
    "#         calculate_dockq=False,\n",
    "#     )\n",
    "    \n",
    "#     # ê²°ê³¼ ì €ì¥\n",
    "#     my_data.export_file(\"results_with_all_metrics_only_rosetta.csv\")\n",
    "\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb0d49d-3199-46aa-a82b-175313ec19f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:50:41.819978Z",
     "iopub.status.busy": "2025-05-26T10:50:41.819526Z",
     "iopub.status.idle": "2025-05-26T10:50:41.835106Z",
     "shell.execute_reply": "2025-05-26T10:50:41.834660Z",
     "shell.execute_reply.started": "2025-05-26T10:50:41.819942Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "import af_analysis\n",
    "from af_analysis import analysis\n",
    "from af_analysis.data import Data\n",
    "\n",
    "# ë¡œê¹… ë ˆë²¨ ì„¤ì •\n",
    "logging.getLogger('pdb_numpy').setLevel(logging.WARNING)  # INFO ë ˆë²¨ì˜ ë¡œê·¸ ìˆ¨ê¹€\n",
    "logging.getLogger('pdb_numpy.coor').setLevel(logging.WARNING)\n",
    "logging.getLogger('pdb_numpy.analysis').setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def time_tracker(description):\n",
    "    \"\"\"ì‹œê°„ ì¸¡ì • ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €\"\"\"\n",
    "    start = time.time()\n",
    "    print(f\"ğŸ”„ Starting: {description}\")\n",
    "    yield\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"âœ… Completed: {description} ({elapsed:.2f}s)\")\n",
    "\n",
    "def calculate_all_metrics_per_query_optimized(query_group_data, **kwargs):\n",
    "    \"\"\"ìµœì í™”ëœ ë‹¨ì¼ query ë©”íŠ¸ë¦­ ê³„ì‚°\"\"\"\n",
    "    query_name, query_df = query_group_data\n",
    "    \n",
    "    print(f\"\\nğŸš€ Processing query: {query_name} ({len(query_df)} models)\")\n",
    "    total_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Data ê°ì²´ ìƒì„±\n",
    "        with time_tracker(\"Data object creation\"):\n",
    "            # ëª¨ë“  í•„ìš”í•œ ì»¬ëŸ¼ì„ í¬í•¨í•˜ì—¬ ìƒì„±\n",
    "            data_dict = {}\n",
    "            for col in query_df.columns:\n",
    "                data_dict[col] = query_df[col].tolist()\n",
    "            \n",
    "            temp_data = Data(data_dict=data_dict)\n",
    "        \n",
    "        # 1. ê¸°ë³¸ AF3 metrics\n",
    "        with time_tracker(\"Basic AF3 metrics\"):\n",
    "            temp_data = (temp_data\n",
    "                        .extract_chain_columns(verbose=False)\n",
    "                        .analyze_chains(verbose=False)\n",
    "                        .add_h3_l3_plddt(verbose=False))  # ì—¬ê¸°ì— ì¶”ê°€\n",
    "                \n",
    "        # 2. Interface metrics\n",
    "        with time_tracker(\"Interface metrics\"):\n",
    "            analysis.add_interface_metrics(temp_data, verbose=False)\n",
    "        \n",
    "        # 3. PPI metrics (ê°€ì¥ ë¹ ë¥¸ ê²ƒë“¤ ë¨¼ì €)\n",
    "        with time_tracker(\"pDockQ calculations\"):\n",
    "            analysis.pdockq(temp_data, verbose=False)\n",
    "            analysis.pdockq2(temp_data, verbose=False)\n",
    "        \n",
    "        with time_tracker(\"LIS matrix\"):\n",
    "            analysis.LIS_matrix(temp_data, verbose=False)\n",
    "        \n",
    "        # 4. piTM/pIS (ì¤‘ê°„ ì‹œê°„ ì†Œìš”)\n",
    "        with time_tracker(\"piTM/pIS calculation\"):\n",
    "            temp_data.add_pitm_pis(cutoff=8.0, verbose=False)\n",
    "        \n",
    "        # 5. RMSD metrics\n",
    "        with time_tracker(\"RMSD calculations\"):\n",
    "            temp_data = (temp_data\n",
    "                        .add_chain_rmsd(align_chain='A', rmsd_chain='H')\n",
    "                        .add_rmsd_scale())\n",
    "        \n",
    "        #6. Rosetta metrics (ê°€ì¥ ì‹œê°„ ì†Œëª¨ì  - ë§ˆì§€ë§‰ì—)\n",
    "        # with time_tracker(\"Rosetta binding energy\"):\n",
    "        #     temp_data.calculate_binding_energy()\n",
    "        \n",
    "        with time_tracker(\"Rosetta interface metrics\"):\n",
    "            temp_data.add_rosetta_metrics(n_jobs=1, verbose=False)\n",
    "        \n",
    "        # 7. DockQ (ì˜µì…˜)\n",
    "        if kwargs.get('calculate_dockq', False):\n",
    "            with time_tracker(\"DockQ calculation\"):\n",
    "                temp_data.prep_dockq(native_dir=kwargs.get('native_dir'), verbose=False)\n",
    "                analysis.calculate_dockq(temp_data, \n",
    "                                       rec_chains='A', lig_chains='H',\n",
    "                                       native_rec_chains='A', native_lig_chains='H',\n",
    "                                       verbose=False)\n",
    "        \n",
    "        total_time = time.time() - total_start\n",
    "        print(f\"âœ¨ Query {query_name} completed in {total_time:.2f}s\")\n",
    "        \n",
    "        return query_name, temp_data.df\n",
    "        \n",
    "    except Exception as e:\n",
    "        total_time = time.time() - total_start\n",
    "        print(f\"âŒ Error processing query {query_name} after {total_time:.2f}s: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        return query_name, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9330e7ec-1615-40e0-b44b-a652e632aa7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:50:43.114568Z",
     "iopub.status.busy": "2025-05-26T10:50:43.114215Z",
     "iopub.status.idle": "2025-05-26T11:03:58.982404Z",
     "shell.execute_reply": "2025-05-26T11:03:58.981090Z",
     "shell.execute_reply.started": "2025-05-26T10:50:43.114535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading /home/cseomoon/project/ABAG/DB/ABAG_structure/AF3/native/6x97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6x97\n",
      "\n",
      "ğŸš€ Processing query: 6x97 (50 models)\n",
      "ğŸ”„ Starting: Data object creation\n",
      "âœ… Completed: Data object creation (0.04s)\n",
      "ğŸ”„ Starting: Basic AF3 metrics\n",
      "âœ… Completed: Basic AF3 metrics (41.19s)\n",
      "ğŸ”„ Starting: Interface metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1249922/1911613693.py:50: DeprecationWarning: add_interface_metrics í•¨ìˆ˜ëŠ” deprecatedë˜ì—ˆìœ¼ë©° í–¥í›„ ë²„ì „ì—ì„œ ì œê±°ë  ì˜ˆì •ì…ë‹ˆë‹¤. ëŒ€ì‹  Data í´ë˜ìŠ¤ì˜ analyze_interfaces ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n",
      "  analysis.add_interface_metrics(temp_data, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed: Interface metrics (80.95s)\n",
      "ğŸ”„ Starting: pDockQ calculations\n",
      "âœ… Completed: pDockQ calculations (15.95s)\n",
      "ğŸ”„ Starting: LIS matrix\n",
      "âœ… Completed: LIS matrix (4.82s)\n",
      "ğŸ”„ Starting: piTM/pIS calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:af_analysis.data:ì²˜ë¦¬ ì¤‘: 6x97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed: piTM/pIS calculation (10.94s)\n",
      "ğŸ”„ Starting: RMSD calculations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:af_analysis.data:6x97: í‰ê·  RMSD = 28.63 Ã…\n",
      "INFO:af_analysis.data:ìŠ¤ì¼€ì¼ë§ëœ RMSD ê´€ë ¨ ì—´ë“¤ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: scaled_rmsd_ratio, scaled_model_RMSD, scaled_query_RMSD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed: RMSD calculations (87.07s)\n",
      "ğŸ”„ Starting: Rosetta interface metrics\n",
      "âœ… Completed: Rosetta interface metrics (435.80s)\n",
      "ğŸ”„ Starting: DockQ calculation\n",
      "âœ… Completed: DockQ calculation (118.73s)\n",
      "âœ¨ Query 6x97 completed in 795.50s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path='/home/cseomoon/project/ABAG/DB/ABAG_structure/AF3/native'\n",
    "query='6x97'\n",
    "\n",
    "target=os.path.join(base_path,query)\n",
    "my_data=Data(directory=target)\n",
    "df=my_data.df\n",
    "\n",
    "# ì˜ˆì‹œ: CSVë¡œë¶€í„° ì½ì–´ì˜¨ DataFrame. 'query' ì»¬ëŸ¼ìœ¼ë¡œ ê·¸ë£¹í™”í•œë‹¤ê³  ê°€ì •\n",
    "for query_name, group_df in df.groupby(\"query\"):\n",
    "    print(query_name)\n",
    "    # calculate_dockq ì˜µì…˜ê³¼ native_dir ì „ë‹¬ ì˜ˆì‹œ\n",
    "    name, result_df = calculate_all_metrics_per_query_optimized(\n",
    "        (query_name, group_df),\n",
    "        calculate_dockq=True,\n",
    "        native_dir=\"/home/cseomoon/project/ABAG/DB/ABAG_structure/original_pdb\"\n",
    "    )\n",
    "    \n",
    "    if result_df is not None:\n",
    "        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê±°ë‚˜ í›„ì²˜ë¦¬\n",
    "        result_df.to_csv(f\"metrics_{name}.csv\", index=False)\n",
    "    else:\n",
    "        print(f\"[Warning] {name} ì²˜ë¦¬ ì‹¤íŒ¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Abnb)",
   "language": "python",
   "name": "abnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
