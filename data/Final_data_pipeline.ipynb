{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced22f6d-e28b-4e57-856c-943a268953d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T08:58:01.452548Z",
     "iopub.status.busy": "2025-05-26T08:58:01.452243Z",
     "iopub.status.idle": "2025-05-26T08:58:01.462066Z",
     "shell.execute_reply": "2025-05-26T08:58:01.461255Z",
     "shell.execute_reply.started": "2025-05-26T08:58:01.452516Z"
    }
   },
   "outputs": [],
   "source": [
    "# import af_analysis\n",
    "# from af_analysis import analysis\n",
    "# from af_analysis.data import Data\n",
    "\n",
    "# def calculate_all_metrics_per_query(query_group_data, **kwargs):\n",
    "#     \"\"\"\n",
    "#     단일 query 그룹에 대해 모든 메트릭을 순차적으로 계산\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     query_group_data : tuple\n",
    "#         (query_name, query_df) 형태의 데이터\n",
    "#     kwargs : dict\n",
    "#         각종 메트릭 계산 옵션들\n",
    "        \n",
    "#     Returns\n",
    "#     -------\n",
    "#     result_df : pd.DataFrame\n",
    "#         모든 메트릭이 계산된 query 데이터\n",
    "#     \"\"\"\n",
    "#     query_name, query_df = query_group_data\n",
    "    \n",
    "#     try:\n",
    "#         # # Data 객체 생성\n",
    "#         temp_data = Data(data_dict={\n",
    "#             'pdb': query_df['pdb'].tolist(),\n",
    "#             'query': query_df['query'].tolist(),\n",
    "#             'data_file': query_df['data_file'].tolist()\n",
    "#             # ... 기타 필요한 컬럼들\n",
    "#         })\n",
    "        \n",
    "#         # # 모든 메트릭 계산 (순차 실행)\n",
    "#         # temp_data = (temp_data\n",
    "#         #             .extract_chain_columns(verbose=False)\n",
    "#         #             .analyze_chains(verbose=False))\n",
    "        \n",
    "#         # # Analysis 함수들\n",
    "#         # from af_analysis import analysis\n",
    "#         # analysis.add_interface_metrics(temp_data, verbose=False)\n",
    "#         # analysis.pdockq(temp_data, verbose=False)\n",
    "#         # analysis.pdockq2(temp_data, verbose=False)\n",
    "        \n",
    "#         # # Data 메서드들\n",
    "#         # temp_data = (temp_data\n",
    "#         #             .add_pitm_pis(cutoff=8.0, verbose=False)\n",
    "#         #             .add_chain_rmsd(align_chain='A', rmsd_chain='H')\n",
    "#         #             .add_rmsd_scale())\n",
    "        \n",
    "#         # Rosetta 메트릭 (multiprocessing 비활성화)\n",
    "#         temp_data = (temp_data.add_rosetta_metrics(n_jobs=1, verbose=False))\n",
    "        \n",
    "#         # DockQ (옵션)\n",
    "#         if kwargs.get('calculate_dockq', False):\n",
    "#             temp_data.prep_dockq(native_dir=kwargs.get('native_dir'), verbose=False)\n",
    "#             analysis.calculate_dockQ(temp_data, \n",
    "#                                    rec_chains='A', lig_chains='H',\n",
    "#                                    native_rec_chains='A', native_lig_chains='H',\n",
    "#                                    verbose=False)\n",
    "        \n",
    "#         return query_name, temp_data.df\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing query {query_name}: {str(e)}\")\n",
    "#         return query_name, None\n",
    "\n",
    "\n",
    "# def calculate_all_metrics_parallel(data_obj, n_jobs=None, **kwargs):\n",
    "#     \"\"\"\n",
    "#     모든 query에 대해 병렬로 메트릭 계산\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data_obj : Data\n",
    "#         전체 데이터 객체\n",
    "#     n_jobs : int, optional\n",
    "#         사용할 CPU 코어 수. None이면 자동 설정\n",
    "#     **kwargs : dict\n",
    "#         메트릭 계산 옵션들\n",
    "        \n",
    "#     Returns\n",
    "#     -------\n",
    "#     updated_data : Data\n",
    "#         모든 메트릭이 계산된 데이터 객체\n",
    "#     \"\"\"\n",
    "#     import multiprocessing as mp\n",
    "#     from functools import partial\n",
    "#     import pandas as pd\n",
    "#     from tqdm.auto import tqdm\n",
    "    \n",
    "#     # Query별로 데이터 그룹화\n",
    "#     query_groups = list(data_obj.df.groupby('query'))\n",
    "    \n",
    "#     if n_jobs is None:\n",
    "#         n_jobs = min(mp.cpu_count(), len(query_groups))\n",
    "    \n",
    "#     print(f\"Processing {len(query_groups)} queries using {n_jobs} CPU cores...\")\n",
    "    \n",
    "#     # 병렬 처리\n",
    "#     worker_func = partial(calculate_all_metrics_per_query, **kwargs)\n",
    "    \n",
    "#     if n_jobs > 1:\n",
    "#         ctx = mp.get_context(\"fork\")\n",
    "#         with ctx.Pool(n_jobs) as pool:\n",
    "#             results = list(tqdm(\n",
    "#                 pool.imap(worker_func, query_groups),\n",
    "#                 total=len(query_groups),\n",
    "#                 desc=\"Processing queries\"\n",
    "#             ))\n",
    "#     else:\n",
    "#         results = [worker_func(group) for group in tqdm(query_groups, desc=\"Processing queries\")]\n",
    "    \n",
    "#     # 결과 통합\n",
    "#     successful_results = []\n",
    "#     failed_queries = []\n",
    "    \n",
    "#     for query_name, result_df in results:\n",
    "#         if result_df is not None:\n",
    "#             successful_results.append(result_df)\n",
    "#         else:\n",
    "#             failed_queries.append(query_name)\n",
    "    \n",
    "#     if failed_queries:\n",
    "#         print(f\"Failed to process {len(failed_queries)} queries: {failed_queries}\")\n",
    "    \n",
    "#     # DataFrame 통합\n",
    "#     if successful_results:\n",
    "#         combined_df = pd.concat(successful_results, ignore_index=True)\n",
    "#         data_obj.df = combined_df\n",
    "#         print(f\"Successfully processed {len(successful_results)} queries\")\n",
    "    \n",
    "#     return data_obj\n",
    "\n",
    "\n",
    "# # 사용 예시\n",
    "# def main():\n",
    "#     # 데이터 로드\n",
    "#     input_data=Data(directory='/home/cseomoon/project/ABAG/2025_H_L_A/20250504_seeds_10/negative/af3_results/results1/6x97_7o9w')\n",
    "#     # my_data.df\n",
    "#     # data = Data(csv=\"your_data.csv\")\n",
    "    \n",
    "#     # 병렬 메트릭 계산\n",
    "#     my_data = calculate_all_metrics_parallel(\n",
    "#         input_data, \n",
    "#         n_jobs=48,  # 8 CPU 코어 사용\n",
    "#         calculate_dockq=False,\n",
    "#     )\n",
    "    \n",
    "#     # 결과 저장\n",
    "#     my_data.export_file(\"results_with_all_metrics_only_rosetta.csv\")\n",
    "\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb0d49d-3199-46aa-a82b-175313ec19f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:50:41.819978Z",
     "iopub.status.busy": "2025-05-26T10:50:41.819526Z",
     "iopub.status.idle": "2025-05-26T10:50:41.835106Z",
     "shell.execute_reply": "2025-05-26T10:50:41.834660Z",
     "shell.execute_reply.started": "2025-05-26T10:50:41.819942Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "import af_analysis\n",
    "from af_analysis import analysis\n",
    "from af_analysis.data import Data\n",
    "\n",
    "# 로깅 레벨 설정\n",
    "logging.getLogger('pdb_numpy').setLevel(logging.WARNING)  # INFO 레벨의 로그 숨김\n",
    "logging.getLogger('pdb_numpy.coor').setLevel(logging.WARNING)\n",
    "logging.getLogger('pdb_numpy.analysis').setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def time_tracker(description):\n",
    "    \"\"\"시간 측정 컨텍스트 매니저\"\"\"\n",
    "    start = time.time()\n",
    "    print(f\"🔄 Starting: {description}\")\n",
    "    yield\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"✅ Completed: {description} ({elapsed:.2f}s)\")\n",
    "\n",
    "def calculate_all_metrics_per_query_optimized(query_group_data, **kwargs):\n",
    "    \"\"\"최적화된 단일 query 메트릭 계산\"\"\"\n",
    "    query_name, query_df = query_group_data\n",
    "    \n",
    "    print(f\"\\n🚀 Processing query: {query_name} ({len(query_df)} models)\")\n",
    "    total_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Data 객체 생성\n",
    "        with time_tracker(\"Data object creation\"):\n",
    "            # 모든 필요한 컬럼을 포함하여 생성\n",
    "            data_dict = {}\n",
    "            for col in query_df.columns:\n",
    "                data_dict[col] = query_df[col].tolist()\n",
    "            \n",
    "            temp_data = Data(data_dict=data_dict)\n",
    "        \n",
    "        # 1. 기본 AF3 metrics\n",
    "        with time_tracker(\"Basic AF3 metrics\"):\n",
    "            temp_data = (temp_data\n",
    "                        .extract_chain_columns(verbose=False)\n",
    "                        .analyze_chains(verbose=False)\n",
    "                        .add_h3_l3_plddt(verbose=False))  # 여기에 추가\n",
    "                \n",
    "        # 2. Interface metrics\n",
    "        with time_tracker(\"Interface metrics\"):\n",
    "            analysis.add_interface_metrics(temp_data, verbose=False)\n",
    "        \n",
    "        # 3. PPI metrics (가장 빠른 것들 먼저)\n",
    "        with time_tracker(\"pDockQ calculations\"):\n",
    "            analysis.pdockq(temp_data, verbose=False)\n",
    "            analysis.pdockq2(temp_data, verbose=False)\n",
    "        \n",
    "        with time_tracker(\"LIS matrix\"):\n",
    "            analysis.LIS_matrix(temp_data, verbose=False)\n",
    "        \n",
    "        # 4. piTM/pIS (중간 시간 소요)\n",
    "        with time_tracker(\"piTM/pIS calculation\"):\n",
    "            temp_data.add_pitm_pis(cutoff=8.0, verbose=False)\n",
    "        \n",
    "        # 5. RMSD metrics\n",
    "        with time_tracker(\"RMSD calculations\"):\n",
    "            temp_data = (temp_data\n",
    "                        .add_chain_rmsd(align_chain='A', rmsd_chain='H')\n",
    "                        .add_rmsd_scale())\n",
    "        \n",
    "        #6. Rosetta metrics (가장 시간 소모적 - 마지막에)\n",
    "        # with time_tracker(\"Rosetta binding energy\"):\n",
    "        #     temp_data.calculate_binding_energy()\n",
    "        \n",
    "        with time_tracker(\"Rosetta interface metrics\"):\n",
    "            temp_data.add_rosetta_metrics(n_jobs=1, verbose=False)\n",
    "        \n",
    "        # 7. DockQ (옵션)\n",
    "        if kwargs.get('calculate_dockq', False):\n",
    "            with time_tracker(\"DockQ calculation\"):\n",
    "                temp_data.prep_dockq(native_dir=kwargs.get('native_dir'), verbose=False)\n",
    "                analysis.calculate_dockq(temp_data, \n",
    "                                       rec_chains='A', lig_chains='H',\n",
    "                                       native_rec_chains='A', native_lig_chains='H',\n",
    "                                       verbose=False)\n",
    "        \n",
    "        total_time = time.time() - total_start\n",
    "        print(f\"✨ Query {query_name} completed in {total_time:.2f}s\")\n",
    "        \n",
    "        return query_name, temp_data.df\n",
    "        \n",
    "    except Exception as e:\n",
    "        total_time = time.time() - total_start\n",
    "        print(f\"❌ Error processing query {query_name} after {total_time:.2f}s: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        return query_name, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9330e7ec-1615-40e0-b44b-a652e632aa7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:50:43.114568Z",
     "iopub.status.busy": "2025-05-26T10:50:43.114215Z",
     "iopub.status.idle": "2025-05-26T11:03:58.982404Z",
     "shell.execute_reply": "2025-05-26T11:03:58.981090Z",
     "shell.execute_reply.started": "2025-05-26T10:50:43.114535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading /home/cseomoon/project/ABAG/DB/ABAG_structure/AF3/native/6x97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6x97\n",
      "\n",
      "🚀 Processing query: 6x97 (50 models)\n",
      "🔄 Starting: Data object creation\n",
      "✅ Completed: Data object creation (0.04s)\n",
      "🔄 Starting: Basic AF3 metrics\n",
      "✅ Completed: Basic AF3 metrics (41.19s)\n",
      "🔄 Starting: Interface metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1249922/1911613693.py:50: DeprecationWarning: add_interface_metrics 함수는 deprecated되었으며 향후 버전에서 제거될 예정입니다. 대신 Data 클래스의 analyze_interfaces 메서드를 사용하세요.\n",
      "  analysis.add_interface_metrics(temp_data, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: Interface metrics (80.95s)\n",
      "🔄 Starting: pDockQ calculations\n",
      "✅ Completed: pDockQ calculations (15.95s)\n",
      "🔄 Starting: LIS matrix\n",
      "✅ Completed: LIS matrix (4.82s)\n",
      "🔄 Starting: piTM/pIS calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:af_analysis.data:처리 중: 6x97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: piTM/pIS calculation (10.94s)\n",
      "🔄 Starting: RMSD calculations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:af_analysis.data:6x97: 평균 RMSD = 28.63 Å\n",
      "INFO:af_analysis.data:스케일링된 RMSD 관련 열들이 추가되었습니다: scaled_rmsd_ratio, scaled_model_RMSD, scaled_query_RMSD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: RMSD calculations (87.07s)\n",
      "🔄 Starting: Rosetta interface metrics\n",
      "✅ Completed: Rosetta interface metrics (435.80s)\n",
      "🔄 Starting: DockQ calculation\n",
      "✅ Completed: DockQ calculation (118.73s)\n",
      "✨ Query 6x97 completed in 795.50s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path='/home/cseomoon/project/ABAG/DB/ABAG_structure/AF3/native'\n",
    "query='6x97'\n",
    "\n",
    "target=os.path.join(base_path,query)\n",
    "my_data=Data(directory=target)\n",
    "df=my_data.df\n",
    "\n",
    "# 예시: CSV로부터 읽어온 DataFrame. 'query' 컬럼으로 그룹화한다고 가정\n",
    "for query_name, group_df in df.groupby(\"query\"):\n",
    "    print(query_name)\n",
    "    # calculate_dockq 옵션과 native_dir 전달 예시\n",
    "    name, result_df = calculate_all_metrics_per_query_optimized(\n",
    "        (query_name, group_df),\n",
    "        calculate_dockq=True,\n",
    "        native_dir=\"/home/cseomoon/project/ABAG/DB/ABAG_structure/original_pdb\"\n",
    "    )\n",
    "    \n",
    "    if result_df is not None:\n",
    "        # 결과를 파일로 저장하거나 후처리\n",
    "        result_df.to_csv(f\"metrics_{name}.csv\", index=False)\n",
    "    else:\n",
    "        print(f\"[Warning] {name} 처리 실패\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Abnb)",
   "language": "python",
   "name": "abnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
